import subprocess
import openai
from pathlib import Path

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OPENAI_API_KEY = "your-api-key"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –∫–ª—é—á
YEK_COMMAND = "yek"  # –ü—É—Ç—å –∫ yek, –µ—Å–ª–∏ –Ω–µ –≤ PATH
MODEL = "gpt-4-turbo"  # –ò–ª–∏ "gpt-3.5-turbo"

def get_project_dump() -> str:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç yek –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–º–ø –ø—Ä–æ–µ–∫—Ç–∞."""
    try:
        result = subprocess.run(
            [YEK_COMMAND],
            capture_output=True,
            text=True,
            check=True
        )
        return result.stdout
    except subprocess.CalledProcessError as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ yek: {e.stderr}")
        raise

def ask_llm(project_dump: str, question: str) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–º–ø –∏ –≤–æ–ø—Ä–æ—Å –≤ OpenAI GPT."""
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    
    response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {
                "role": "system",
                "content": "–¢—ã senior developer. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ–µ–∫—Ç –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
            },
            {
                "role": "user",
                "content": f"–ü—Ä–æ–µ–∫—Ç:\n{project_dump}\n\n–í–æ–ø—Ä–æ—Å: {question}"
            }
        ],
        temperature=0.3  # –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    )
    return response.choices[0].message.content

def main():
    print("‚ö° –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ —á–µ—Ä–µ–∑ yek + GPT...")
    project_dump = get_project_dump()
    
    question = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—á—É: ")
    answer = ask_llm(project_dump, question)
    
    print("\nüîß –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç GPT:")
    print(answer)

if __name__ == "__main__":
    main()